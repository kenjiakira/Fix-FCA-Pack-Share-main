const fs = require('fs');
const path = require('path');
const { Canvas, Image, ImageData, loadImage } = require('canvas');
const faceapi = require('face-api.js');
const axios = require('axios');

const cacheDir = path.join(__dirname, 'cache');
if (!fs.existsSync(cacheDir)) {
  fs.mkdirSync(cacheDir);
}

faceapi.env.monkeyPatch({ Canvas, Image, ImageData });

module.exports = {
  name: "age",
  dev: "HNT",
  usedby: 0,
  category: "Media",
  info: "ÄoÃ¡n tuá»•i vÃ  cáº£m xÃºc cá»§a ngÆ°á»i trong áº£nh",
  usages: "[reply áº£nh]",
  onPrefix: true,
  cooldowns: 5,

  onLaunch: async function({ api, event }) {
    const { threadID, messageID, messageReply } = event;

    if (!messageReply || !messageReply.attachments || messageReply.attachments.length === 0) {
      return api.sendMessage("Vui lÃ²ng reply má»™t áº£nh Ä‘á»ƒ bot Ä‘oÃ¡n tuá»•i.", threadID, messageID);
    }

    const attachment = messageReply.attachments[0];
    if (attachment.type === 'video' || attachment.type === 'animated_image') {
      return api.sendMessage("Bot khÃ´ng há»— trá»£ phÃ¢n tÃ­ch video hoáº·c GIF. Vui lÃ²ng gá»­i áº£nh.", threadID, messageID);
    }

    try {
      const waitMessage = await api.sendMessage("â³ Äang phÃ¢n tÃ­ch khuÃ´n máº·t...", threadID);

      await Promise.all([
        faceapi.nets.ssdMobilenetv1.loadFromDisk('../assets/models'),
        faceapi.nets.faceLandmark68Net.loadFromDisk('../assets/models'),
        faceapi.nets.faceRecognitionNet.loadFromDisk('../assets/models'),
        faceapi.nets.ageGenderNet.loadFromDisk('../assets/models/'),
        faceapi.nets.faceExpressionNet.loadFromDisk('../assets/models'),
        faceapi.nets.tinyFaceDetector.loadFromDisk('../assets/models')
      ]);

      const imageUrl = attachment.url;
      const imageFileName = `image_${Date.now()}.jpg`;
      const imagePath = path.join(cacheDir, imageFileName);

      const response = await axios({
        url: imageUrl,
        responseType: 'stream',
      });

      await new Promise((resolve, reject) => {
        response.data.pipe(fs.createWriteStream(imagePath))
          .on('finish', resolve)
          .on('error', reject);
      });

      const imgBuffer = fs.readFileSync(imagePath);
      const image = await loadImage(imgBuffer);

      const detections = await faceapi
        .detectAllFaces(image)
        .withFaceLandmarks()
        .withFaceExpressions()
        .withAgeAndGender();

      if (detections.length === 0) {
        fs.unlinkSync(imagePath);
        return api.sendMessage("Bot khÃ´ng phÃ¡t hiá»‡n khuÃ´n máº·t nÃ o trong áº£nh. Vui lÃ²ng gá»­i áº£nh khÃ¡c.", threadID, messageID);
      }

      const canvas = faceapi.createCanvasFromMedia(image);
      const ctx = canvas.getContext('2d');
      ctx.drawImage(image, 0, 0);

      detections.forEach(detection => {
        const box = detection.detection.box;
        const drawBox = new faceapi.draw.DrawBox(box, {
          label: `${Math.round(detection.age)}T (${detection.gender})`,
          boxColor: detection.gender === 'male' ? '#00ff00' : '#ff00ff'
        });
        drawBox.draw(canvas);

        const expressions = detection.expressions;
        const mainExpression = Object.entries(expressions)
          .reduce((a, b) => a[1] > b[1] ? a : b)[0];
        
        ctx.font = '16px Arial';
        ctx.fillStyle = '#ffffff';
        ctx.fillText(`${mainExpression} (${Math.round(expressions[mainExpression] * 100)}%)`, 
          box.x, box.y - 5);
      });

      const outputPath = path.join(cacheDir, `analyzed_${Date.now()}.jpg`);
      const stream = canvas.createJPEGStream();
      await new Promise((resolve, reject) => {
        stream.pipe(fs.createWriteStream(outputPath))
          .on('finish', resolve)
          .on('error', reject);
      });

      let analysis = `ğŸ“Š Káº¿t quáº£ phÃ¢n tÃ­ch:\n\n`;
      detections.forEach((detection, index) => {
        const age = Math.round(detection.age);
        const gender = detection.gender === 'male' ? 'Nam' : 'Ná»¯';
        const mainEmotion = Object.entries(detection.expressions)
          .reduce((a, b) => a[1] > b[1] ? a : b)[0];

        analysis += `ğŸ‘¤ NgÆ°á»i ${index + 1}:\n`;
        analysis += `â”œâ”€ Tuá»•i: ${age}\n`;
        analysis += `â”œâ”€ Giá»›i tÃ­nh: ${gender}\n`;
        analysis += `â”œâ”€ Cáº£m xÃºc: ${translateEmotion(mainEmotion)}\n`;
        analysis += `â””â”€ ÄÃ¡nh giÃ¡: ${getBeautyRating(age, gender)}\n\n`;
      });

      await api.sendMessage({
        body: analysis,
        attachment: fs.createReadStream(outputPath)
      }, threadID, () => {
        fs.unlinkSync(outputPath);
        api.unsendMessage(waitMessage.messageID);
      }, messageID);

    } catch (error) {
      console.error("Lá»—i khi phÃ¢n tÃ­ch khuÃ´n máº·t:", error);
      api.sendMessage("ÄÃ£ xáº£y ra lá»—i khi phÃ¢n tÃ­ch áº£nh. Vui lÃ²ng thá»­ láº¡i sau.", threadID, messageID);
    }
  }
};

function translateEmotion(emotion) {
  const emotions = {
    'happy': 'Vui váº» ğŸ˜Š',
    'sad': 'Buá»“n bÃ£ ğŸ˜¢',
    'angry': 'Tá»©c giáº­n ğŸ˜ ',
    'fearful': 'Lo sá»£ ğŸ˜¨',
    'disgusted': 'GhÃª tá»Ÿm ğŸ¤¢',
    'surprised': 'Ngáº¡c nhiÃªn ğŸ˜²',
    'neutral': 'BÃ¬nh thÆ°á»ng ğŸ˜'
  };
  return emotions[emotion] || emotion;
}

function getBeautyRating(age, gender) {
  const ratings = [
    "Ráº¥t cuá»‘n hÃºt âœ¨",
    "Xinh Ä‘áº¹p/Äáº¹p trai ğŸŒŸ",
    "Dá»… thÆ°Æ¡ng ğŸ’",
    "CÃ³ duyÃªn ğŸŒ¸",
    "BÃ¬nh thÆ°á»ng ğŸŒ¼"
  ];
  return ratings[Math.floor(Math.random() * ratings.length)];
}
