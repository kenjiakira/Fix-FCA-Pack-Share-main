To install the official Node.js library, run the following command in your Node.js project directory:

npm install elevenlabs


Authentication

API Keys
The ElevenLabs API uses API keys for authentication. Every request to the API must include your API key, used to authenticate your requests and track usage quota.

Each API key can be scoped to one of the following:

Scope restriction: Set access restrictions by limiting which API endpoints the key can access.
Credit quota: Define custom credit limits to control usage.
Remember that your API key is a secret. Do not share it with others or expose it in any client-side code (browsers, apps).

All API requests should include your API key in an xi-api-key HTTP header as follows:

xi-api-key: ELEVENLABS_API_KEY

Making requests
You can paste the command below into your terminal to run your first API request. Make sure to replace $ELEVENLABS_API_KEY with your secret API key.

curl 'https://api.elevenlabs.io/v1/models' \
  -H 'Content-Type: application/json' \
  -H 'xi-api-key: $ELEVENLABS_API_KEY'

Example with the elevenlabs Python package:

from elevenlabs.client import ElevenLabs
client = ElevenLabs(
  api_key='YOUR_API_KEY',
)

Example with the elevenlabs Node.js package:

import { ElevenLabsClient } from 'elevenlabs';
const client = new ElevenLabsClient({
  apiKey: 'YOUR_API_KEY',
});

Streaming

The ElevenLabs API supports real-time audio streaming for select endpoints, returning raw audio bytes (e.g., MP3 data) directly over HTTP using chunked transfer encoding. This allows clients to process or play audio incrementally as it is generated.

Our official Node and Python libraries include utilities to simplify handling this continuous audio stream.

Streaming is supported for the Text to Speech API, Voice Changer API & Audio Isolation API. This section focuses on how streaming works for requests made to the Text to Speech API.

In Python, a streaming request looks like:

from elevenlabs import stream
from elevenlabs.client import ElevenLabs
client = ElevenLabs()
audio_stream = client.text_to_speech.convert_as_stream(
    text="This is a test",
    voice_id="JBFqnCBsd6RMkjVDRZzb",
    model_id="eleven_multilingual_v2"
)
# option 1: play the streamed audio locally
stream(audio_stream)
# option 2: process the audio bytes manually
for chunk in audio_stream:
    if isinstance(chunk, bytes):
        print(chunk)

In Node / Typescript, a streaming request looks like:

WebSockets
Handshake
GET

wss://api.elevenlabs.io/v1/text-to-speech/:voice_id/stream-input

Path parameters
voice_id
string
Required
The unique identifier for the voice to use in the TTS process.

Query parameters
model_id
string
Optional
The model ID to use

language_code
string
Optional
The ISO 639-1 language code (for Turbo v2.5 and Flash v2.5 models only)

enable_logging
string
Optional
Whether to enable logging of the request

enable_ssml_parsing
boolean
Optional
Defaults to false
Whether to enable SSML parsing

optimize_streaming_latency
enum
Optional
Defaults to mp3_44100
Latency optimization level (deprecated)


Show 6 enum values
output_format
enum
Optional
Defaults to mp3_44100
The output audio format


Show 6 enum values
inactivity_timeout
double
Optional
Defaults to 20
Timeout for inactivity before connection is closed

sync_alignment
boolean
Optional
Defaults to false
Whether to include timing data with every audio chunk

auto_mode
boolean
Optional
Defaults to false
This parameter focuses on reducing the latency by disabling the chunk schedule and all buffers. It is only recommended when sending full sentences or phrases, sending partial phrases will result in highly reduced quality. By default it’s set to false.

Send
Initialize Connection
object

Show 4 properties
OR
Send Text
object

Show 5 properties
OR
Close Connection
object

Show property
Receive
Audio Output
object

Show property
OR
Final Output
object

Show 3 properties
Handshake

Play
URL	wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input
Method	GET
Status	101 Switching Protocols
Messages

{"text":" ","voice_settings":{"stability":0.5,"similarity_boost":0.8},"xi-api-key":"xi-api-key"}
publish


{"text":"Hello World","try_trigger_generation":true}
publish


{"text":""}
publish


{"audio":"Y3VyaW91cyBtaW5kcyB0aGluayBhbGlrZSA6KQ=="}
subscribe

ENDPOINTS
Text to speech
Create speech
POST


https://api.elevenlabs.io
/v1/text-to-speech/:voice_id
Convert text to speech using our library of over 3,000 voices across 32 languages.

Path parameters
voice_id
string
Required
ID of the voice to be used. Use the Get voices endpoint list all the available voices.

Query parameters
enable_logging
boolean
Optional
Defaults to true
When enable_logging is set to false full privacy mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Full privacy mode may only be used by enterprise customers.

optimize_streaming_latency
integer
Optional
Deprecated
You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).

Defaults to None.

output_format
enum
Optional
The output format of the generated audio.


Show 11 enum values
Request
This endpoint expects an object.
text
string
Required
The text that will get converted into speech.

model_id
string
Optional
Defaults to eleven_monolingual_v1
Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.

language_code
string
Optional
Language code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 supports language enforcement. For other models, an error will be returned if language code is provided.

voice_settings
object
Optional
Voice settings overriding stored setttings for the given voice. They are applied only on the given request.


Show 4 properties
pronunciation_dictionary_locators
list of objects
Optional
A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request


Show 2 properties
seed
integer
Optional
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.

previous_text
string
Optional
The text that came before the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

next_text
string
Optional
The text that comes after the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

previous_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.

next_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.

use_pvc_as_ivc
boolean
Optional
Defaults to false
If true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.

apply_text_normalization
enum
Optional
Defaults to auto
Allowed values:
auto
on
off
This parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.

Response
Successful Response

ENDPOINTS
Text to speech
Create speech with timing
POST


https://api.elevenlabs.io
/v1/text-to-speech/:voice_id/with-timestamps
Generate speech from text with precise character-level timing information for audio-text synchronization.

Path parameters
voice_id
string
Required
ID of the voice to be used. Use the Get voices endpoint list all the available voices.

Query parameters
enable_logging
boolean
Optional
Defaults to true
When enable_logging is set to false full privacy mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Full privacy mode may only be used by enterprise customers.

optimize_streaming_latency
integer
Optional
Deprecated
You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).

Defaults to None.

output_format
enum
Optional
The output format of the generated audio.


Show 11 enum values
Request
This endpoint expects an object.
text
string
Required
The text that will get converted into speech.

model_id
string
Optional
Defaults to eleven_monolingual_v1
Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.

language_code
string
Optional
Language code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 supports language enforcement. For other models, an error will be returned if language code is provided.

voice_settings
object
Optional
Voice settings overriding stored setttings for the given voice. They are applied only on the given request.


Show 4 properties
pronunciation_dictionary_locators
list of objects
Optional
A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request


Show 2 properties
seed
integer
Optional
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.

previous_text
string
Optional
The text that came before the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

next_text
string
Optional
The text that comes after the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

previous_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.

next_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.

use_pvc_as_ivc
boolean
Optional
Defaults to false
If true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.

apply_text_normalization
enum
Optional
Defaults to auto
Allowed values:
auto
on
off
This parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.

Response
Successful Response

ENDPOINTS
Text to speech
Stream speech
POST


https://api.elevenlabs.io
/v1/text-to-speech/:voice_id/stream
Convert text to speech in real-time using our library of over 3,000 voices across 32 languages.

Path parameters
voice_id
string
Required
ID of the voice to be used. Use the Get voices endpoint list all the available voices.

Query parameters
enable_logging
boolean
Optional
Defaults to true
When enable_logging is set to false full privacy mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Full privacy mode may only be used by enterprise customers.

optimize_streaming_latency
integer
Optional
Deprecated
You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).

Defaults to None.

output_format
enum
Optional
The output format of the generated audio.


Show 11 enum values
Request
This endpoint expects an object.
text
string
Required
The text that will get converted into speech.

model_id
string
Optional
Defaults to eleven_monolingual_v1
Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.

language_code
string
Optional
Language code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 supports language enforcement. For other models, an error will be returned if language code is provided.

voice_settings
object
Optional
Voice settings overriding stored setttings for the given voice. They are applied only on the given request.


Show 4 properties
pronunciation_dictionary_locators
list of objects
Optional
A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request


Show 2 properties
seed
integer
Optional
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.

previous_text
string
Optional
The text that came before the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

next_text
string
Optional
The text that comes after the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

previous_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.

next_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.

use_pvc_as_ivc
boolean
Optional
Defaults to false
If true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.

apply_text_normalization
enum
Optional
Defaults to auto
Allowed values:
auto
on
off
This parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.

Response
Successful Response

ENDPOINTS
Text to speech
Stream speech with timing
POST


https://api.elevenlabs.io
/v1/text-to-speech/:voice_id/stream/with-timestamps
Stream speech from text with precise character-level timing information for audio-text synchronization.

Path parameters
voice_id
string
Required
ID of the voice to be used. Use the Get voices endpoint list all the available voices.

Query parameters
enable_logging
boolean
Optional
Defaults to true
When enable_logging is set to false full privacy mode will be used for the request. This will mean history features are unavailable for this request, including request stitching. Full privacy mode may only be used by enterprise customers.

optimize_streaming_latency
integer
Optional
Deprecated
You can turn on latency optimizations at some cost of quality. The best possible final latency varies by model. Possible values: 0 - default mode (no latency optimizations) 1 - normal latency optimizations (about 50% of possible latency improvement of option 3) 2 - strong latency optimizations (about 75% of possible latency improvement of option 3) 3 - max latency optimizations 4 - max latency optimizations, but also with text normalizer turned off for even more latency savings (best latency, but can mispronounce eg numbers and dates).

Defaults to None.

output_format
enum
Optional
The output format of the generated audio.


Show 11 enum values
Request
This endpoint expects an object.
text
string
Required
The text that will get converted into speech.

model_id
string
Optional
Defaults to eleven_monolingual_v1
Identifier of the model that will be used, you can query them using GET /v1/models. The model needs to have support for text to speech, you can check this using the can_do_text_to_speech property.

language_code
string
Optional
Language code (ISO 639-1) used to enforce a language for the model. Currently only Turbo v2.5 supports language enforcement. For other models, an error will be returned if language code is provided.

voice_settings
object
Optional
Voice settings overriding stored setttings for the given voice. They are applied only on the given request.


Show 4 properties
pronunciation_dictionary_locators
list of objects
Optional
A list of pronunciation dictionary locators (id, version_id) to be applied to the text. They will be applied in order. You may have up to 3 locators per request


Show 2 properties
seed
integer
Optional
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be integer between 0 and 4294967295.

previous_text
string
Optional
The text that came before the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

next_text
string
Optional
The text that comes after the text of the current request. Can be used to improve the flow of prosody when concatenating together multiple generations or to influence the prosody in the current generation.

previous_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both previous_text and previous_request_ids is send, previous_text will be ignored. A maximum of 3 request_ids can be send.

next_request_ids
list of strings
Optional
A list of request_id of the samples that were generated before this generation. Can be used to improve the flow of prosody when splitting up a large task into multiple requests. The results will be best when the same model is used across the generations. In case both next_text and next_request_ids is send, next_text will be ignored. A maximum of 3 request_ids can be send.

use_pvc_as_ivc
boolean
Optional
Defaults to false
If true, we won’t use PVC version of the voice for the generation but the IVC version. This is a temporary workaround for higher latency in PVC versions.

apply_text_normalization
enum
Optional
Defaults to auto
Allowed values:
auto
on
off
This parameter controls text normalization with three modes: ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ model.

Response
Stream of JSON objects containing audio chunks and character timing information

audio_base64
string
Optional
Base64 encoded audio chunk

alignment
object
Optional

Show 3 properties
normalized_alignment
object
Optional

Show 3 properties